---
title: 负载均衡解决方案
toc: true
clearReading: true
metaAlignment: center
categories: 解决方案
tags: Web
keywords: 负载均衡
excerpt: 本文主要讲解常见的负载均衡相关知识
---
## 概述

:question:什么是负载均衡？

{% alert success no-icon%}

负载均衡，英文名称为Load Balance，指由多台服务器以对称的方式组成一个服务器集合，每台服务器都具有等价的地位，都可以单独对外提供服务而无须其他服务器的辅助。通过某种负载分担算法，将外部发送来的请求均匀分配到对称结构中的某一台服务器上，而接收到请求的服务器独立地回应客户的请求

{% endalert%}

简单的理解，负载均衡就是将请求**均匀分摊**在多个操作单元上执行，负载均衡的关键就在于**均匀**

{% alert success no-icon%}

:sparkles:负载均衡能够平均分配客户请求到服务器阵列，借此提供快速获取重要数据，解决大量并发访问服务问题，这种集群技术可以用最少的投资获得接近于大型主机的性能

{% endalert%}

:book:负载均衡分为软件负载均衡和硬件负载均衡，前者的代表是阿里章文嵩博士研发的`LVS`，后者则是均衡服务器比如`F5`
{% image fancybox fig-100  center https://gitee.com/mingchaohu/blog-image/raw/master/image/loadBalanceer.png %}

## 常用的负载均衡算法
:dart:本小节将主要介绍常用的负载均衡算法
### 轮询法
{% alert success no-icon%}

将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载
{%endalert%}

由于serverWeightMap中的地址列表是动态的，随时可能有机器上线、下线或者宕机，因此为了避免可能出现的并发问题，方法内部要新建局部变量serverMap，现将serverMap中的内容复制到线程本地，以避免被多个线程修改。这样可能会引入新的问题，复制以后serverWeightMap的修改无法反映给serverMap，也就是说这一轮选择服务器的过程中，新增服务器或者下线服务器，负载均衡算法将无法获知。新增无所谓，如果有服务器下线或者宕机，那么可能会访问到不存在的地址。因此，服务调用端需要有相应的容错处理，比如重新发起一次server选择并调用。

对于当前轮询的位置变量pos，为了保证服务器选择的顺序性，需要在操作时对其加锁，使得同一时刻只能有一个线程可以修改pos的值，否则当pos变量被并发修改，则无法保证服务器选择的顺序性，甚至有可能导致keyList数组越界。

轮询法的优点在于：试图做到请求转移的绝对均衡。

轮询法的缺点在于：为了做到请求转移的绝对均衡，必须付出相当大的代价，因为为了保证pos变量修改的互斥性，需要引入重量级的悲观锁synchronized，这将会导致该段轮询代码的并发吞吐量发生明显的下降。
### 加权轮询法
{% alert success no-icon%}

不同的后端服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不相同。给配置高、负载低的机器配置更高的权重，让其处理更多的请；而配置低、负载高的机器，给其分配较低的权重，降低其系统负载，加权轮询能很好地处理这一问题，并将请求顺序且按照权重分配到后端
{%endalert%}



### 平滑加权轮询



### 随机法
{% alert success no-icon%}

通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。由概率统计理论可以得知，随着客户端调用服务端的次数增多，其实际效果越来越接近于平均分配调用量到后端的每一台服务器，也就是轮询的结果
{%endalert%}
整体代码思路和轮询法一致，先重建serverMap，再获取到server列表。在选取server的时候，通过Random的nextInt方法取0~keyList.size()区间的一个随机值，从而从服务器列表中随机获取到一台服务器地址进行返回。基于概率统计的理论，吞吐量越大，随机算法的效果越接近于轮询算法的效果
### 加权随机法
{% alert success no-icon%}

与加权轮询法一样，加权随机法也根据后端机器的配置，系统的负载分配不同的权重。不同的是，它是按照权重随机请求后端服务器，而非顺序
{%endalert%}



### 源地址哈希法



### 最小连接数法

最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它是根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前的请求，尽可能地提高后端服务的利用效率，将负责合理地分流到每一台服务器

### 一致性哈希



## 负载均衡方案
常见互联网分布式架构如上，分为：客户端层、反向代理层、站点层、服务层、数据层

可以看到，每一个下游都有多个上游调用，只需要做到，每一个上游都均匀访问每一个下游，就能实现整体的均匀分摊
### 第一层：客户端层到反向代理层

### 第二层：反向代理层到站点层

### 第三层：站点层到服务层

### 第四层：访问数据层
在数据量很大的情况下，由于数据层（db/cache）涉及数据的水平切分，所以数据层的负载均衡更为复杂一些，它分为“数据的均衡”，与“请求的均衡”。

数据的均衡是指：水平切分后的每个服务（db/cache），数据量是均匀的。

请求的均衡是指：水平切分后的每个服务（db/cache），请求量是均匀的。
业内常见的水平切分方式有这么几种：
#### 按照range水平切分

#### 按照id哈希水平切分

### 总结
## 附录

[几种简单的负载均衡算法及其Java代码实现](https://www.cnblogs.com/xrq730/p/5154340.html)
[负载均衡的6种算法，Ngnix的5种算法！](https://zhuanlan.zhihu.com/p/68733507)
[关于负载均衡的一切](https://mp.weixin.qq.com/s/xvozZjmn-CvmQMAEAyDc3w)

https://xie.infoq.cn/article/cd04a63335e3bd42298809fdb

https://zhuanlan.zhihu.com/p/61847281

https://cloud.tencent.com/developer/article/1437969

https://developer.51cto.com/art/201904/595761.htm

https://zhuanlan.zhihu.com/p/60783609

https://zhuanlan.zhihu.com/p/81779042

https://cloud.tencent.com/developer/article/1722295

https://dubbo.apache.org/zh/docs/advanced/loadbalance/

https://www.jianshu.com/p/d7e173d212a8
[吃透负载均衡](https://mp.weixin.qq.com/s/-mhDf-h2vodNKxQqy5u7mg)